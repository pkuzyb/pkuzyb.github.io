<html> 	
<head>
<title>Yubin Zhang</title>
<meta name="description" content="Yubin Zhang's personal website" />
<meta name="keywords" content="phonetics, phonology, psycholinguistics, neurolinguistics, speech production, speech perception" />
<meta name="author" content="Yubin Zhang" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="css/mycss.css" rel="stylesheet" type="text/css" />
</head>

<table class = "center">
<tr>
<td class="name" ><i>Yubin Zhang</i>
</td>
<td class="title">
<b> Resources <b/>
<hr align="left" class="hrzl" color="green" />
</td>
</tr>

<tr>
<td class="sidebar">
<p>
<a  href="index.html">Home</a><br>
<a  href="projects.html">Projects</a><br>
<a  href="output.html">Research Output</a><br>
<a  href="CV.html">Curriculum Vitae</a><br>
<a  href="resources.html">Resources</a><br>
<a  href="moments.html">Moments</a><br>
</p>
</td>

<td class="content">
<div class= "scrollable">
   <p class ="subtitle"><b> Real-time MRI Tools </b><br> </p>
   <p class ="subsubtitle"><i>&#x25cf; A app for inspecting and editing articulator contour tracks  (under development) </i></p>
   <center> <img  class = "rectMRI" src=./pics/rectMRI.png></center><br>
     <p class ="subsubtitle"><i>&#x25cf; A toolbox for gestural analysis based on articulator contour tracks (under development) </i></p>
    <p>It allows semi-automatic track-based gestural analysis for rt-MRI videos.  Gestural landmarks are automatically generated based on some initial annotations. They can be manually adjusted and readily exported for statistical analysis.</p>
        <center> <img  class = "mrigest" src=./pics/mri_gest.png></center><br>
    <p class ="subsubtitle"><i>&#x25cf; A toolbox for analyzing respiratory gestures in speech (under development) </i></p>
   <center> <img  class = "respgest" src=./pics/resp_gest.png></center><br>
   
   </div>
<hr align="left" class="hrzl" color="green" />
</td>
</table>
</body>
</html>
